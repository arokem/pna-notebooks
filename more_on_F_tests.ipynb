{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "The hidden truth on F-tests and contrasts "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We know that the traditional way of looking at an F-contrast is to think of two models : a full model $X$, and a reduced model $X_0$, and compute the sum of square of the residuals under these two models. We also know that we can express the numerator of an F test with a contrast that impose a constraint on the parameters of the model. This short notebook is to make clear the relation between these two formulations, and therefore being able to test unusual hypotheses more easily. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.linalg as lin\n",
      "import scipy.stats as sst\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 30\n",
      "\n",
      "# make a design of 1 factor 3 levels\n",
      "oneway_anov = np.kron(np.eye(3), ones((10,1)))\n",
      "\n",
      "#add a trend?\n",
      "#trend = np.arange(0,n).reshape(n,1)\n",
      "\n",
      "# add an intercept\n",
      "intercept = np.ones((n,1))\n",
      "\n",
      "X = np.hstack((oneway_anov, intercept))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.  0.  0.  1.]\n",
        " [ 1.  0.  0.  1.]\n",
        " [ 1.  0.  0.  1.]\n",
        " [ 1.  0.  0.  1.]\n",
        " [ 1.  0.  0.  1.]\n",
        " [ 1.  0.  0.  1.]\n",
        " [ 1.  0.  0.  1.]\n",
        " [ 1.  0.  0.  1.]\n",
        " [ 1.  0.  0.  1.]\n",
        " [ 1.  0.  0.  1.]\n",
        " [ 0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.]\n",
        " [ 0.  0.  1.  1.]\n",
        " [ 0.  0.  1.  1.]\n",
        " [ 0.  0.  1.  1.]\n",
        " [ 0.  0.  1.  1.]\n",
        " [ 0.  0.  1.  1.]\n",
        " [ 0.  0.  1.  1.]\n",
        " [ 0.  0.  1.  1.]\n",
        " [ 0.  0.  1.  1.]\n",
        " [ 0.  0.  1.  1.]\n",
        " [ 0.  0.  1.  1.]]\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n, p = X.shape\n",
      "\n",
      "Y = np.random.randn(n, 1)\n",
      "\n",
      "csignal = np.array([1., -1., 0, 3.]).reshape(4,1)\n",
      "signal = X.dot(csignal)\n",
      "Y +=  signal\n",
      "\n",
      "print np.hstack((Y, X))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 2.77986271  1.          0.          0.          1.        ]\n",
        " [ 3.99773182  1.          0.          0.          1.        ]\n",
        " [ 3.7271806   1.          0.          0.          1.        ]\n",
        " [ 3.8632183   1.          0.          0.          1.        ]\n",
        " [ 4.20122298  1.          0.          0.          1.        ]\n",
        " [ 4.1900779   1.          0.          0.          1.        ]\n",
        " [ 3.23495586  1.          0.          0.          1.        ]\n",
        " [ 3.49377632  1.          0.          0.          1.        ]\n",
        " [ 3.80760708  1.          0.          0.          1.        ]\n",
        " [ 4.15341048  1.          0.          0.          1.        ]\n",
        " [ 1.10881459  0.          1.          0.          1.        ]\n",
        " [ 1.45459043  0.          1.          0.          1.        ]\n",
        " [ 1.49804018  0.          1.          0.          1.        ]\n",
        " [ 2.04922078  0.          1.          0.          1.        ]\n",
        " [ 2.81045098  0.          1.          0.          1.        ]\n",
        " [ 0.11316675  0.          1.          0.          1.        ]\n",
        " [ 2.58020441  0.          1.          0.          1.        ]\n",
        " [ 0.17984951  0.          1.          0.          1.        ]\n",
        " [ 2.83416135  0.          1.          0.          1.        ]\n",
        " [ 0.83353014  0.          1.          0.          1.        ]\n",
        " [ 2.98371249  0.          0.          1.          1.        ]\n",
        " [ 3.74146005  0.          0.          1.          1.        ]\n",
        " [ 3.39001635  0.          0.          1.          1.        ]\n",
        " [ 2.33916425  0.          0.          1.          1.        ]\n",
        " [ 3.51469752  0.          0.          1.          1.        ]\n",
        " [ 4.16145559  0.          0.          1.          1.        ]\n",
        " [ 3.68332627  0.          0.          1.          1.        ]\n",
        " [ 3.08862975  0.          0.          1.          1.        ]\n",
        " [ 2.86829704  0.          0.          1.          1.        ]\n",
        " [ 3.266467    0.          0.          1.          1.        ]]\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "F test with a known reduced model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's imaging that we know the reduced model: we'd like to test what is in $X$ but not in $X_0$.\n",
      "\n",
      "We define the orthogonal projector onto $X$ as $P_X = X X^-$, where $X^-$ is the moore-penrose pseudo inverse.\n",
      "\n",
      "\\begin{eqnarray} \n",
      "%\\label{equ:F} \n",
      "  F_{\\nu_1, \\nu_2} & = & \\frac{(Y^T(I-P_{X_0})Y - Y^T(I-P_{X})Y)/ \\nu_{1} }{Y^T(I-P_{X})Y/\\nu_{2}} \\\\ \n",
      "  \t\t& = & \\frac{(SSR(X_0) - SSR(X))/\\nu_1}{SSR(X)/\\nu_2}\n",
      "\\end{eqnarray}\n",
      "\n",
      "with $SSR(X)$, (resp. $SSR(X_0)$) the sum of square for error of model $X$ (resp. $X_0$), and\n",
      "\n",
      "\\begin{eqnarray} \n",
      "  \\nu_{1} & =  & tr(P_X - P_{X_0}) = tr(R_0 - R_X) \\\\ \\nonumber \\nu_{2} & = & tr(I - P_X) = tr(R_X) \n",
      "\\end{eqnarray}\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy.linalg import matrix_rank"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# lets do an F-test : \n",
      "\n",
      "def F_test(Y, X, L0):\n",
      "    '''\n",
      "    Y: numpy array\n",
      "        data\n",
      "    X: numpy array\n",
      "        design matrix\n",
      "    L0: numpy array\n",
      "        contrast forming X0, the \"null\" model\n",
      "    \n",
      "    returns: \n",
      "    \n",
      "    F, nu1, nu2 : float\n",
      "    '''\n",
      "    X0 = X.dot(L0)\n",
      "    n  = X.shape[0]\n",
      "    p0 = matrix_rank(X0)\n",
      "    p = matrix_rank(X)\n",
      "    \n",
      "    nu1 = p-p0\n",
      "    nu2 = n-p\n",
      "\n",
      "    SSR_num = (Y.T.dot(proj(X, Y)) - Y.T.dot(proj(X0, Y)))\n",
      "    numF = SSR_num/nu1\n",
      "    print '    ', SSR_num, p, p0\n",
      "    SSR_den = (Y.T.dot(R_proj(X, Y)))\n",
      "    denF = SSR_den/nu2\n",
      "    print '    ', SSR_den, n, p\n",
      "    \n",
      "    return numF/denF, nu1, nu2\n",
      "\n",
      "    \n",
      "def proj(X, Y=None):\n",
      "    # project onto the space of X\n",
      "    #print matrix_rank(X)\n",
      "    [u, s, vt] = lin.svd(X, full_matrices=False)\n",
      "    tol = s.max() * max(X.shape) * finfo(s.dtype).eps\n",
      "    nz = np.where(s > tol)[0]\n",
      "    #print nz\n",
      "    if Y is None:\n",
      "        return u[:,nz].dot(u[:,nz].T)\n",
      "    else:\n",
      "        return u[:,nz].dot(u[:,nz].T.dot(Y))\n",
      "    \n",
      "def R_proj(X, Y=None):\n",
      "    # project onto the space orthogonal to X (RY) \n",
      "    if Y is None:\n",
      "        return np.eye(X.shape[0]) - proj(X, Y) \n",
      "    else:\n",
      "        return Y - proj(X, Y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Understanding the numerator : Matthew's proposal - works under some conditions:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At line $i$ :\n",
      "\n",
      "$$\n",
      "\\begin{eqnarray}\n",
      "\\epsilon_{0i}^2 - \\epsilon_i^2 &=& (Y - \\mu)^2  - (Y - \\beta_{i} - \\mu)^2 \\\\\n",
      "                            &=& \\epsilon_{0i}^2 - (\\epsilon_{0i} - \\beta_{i})^2 \\\\\n",
      "                            &=& \\beta_i^2 + 2\\epsilon_{0i}\\beta_{i}\n",
      "\\end{eqnarray}\n",
      "$$\n",
      "\n",
      "Summing these, we see that  $\\sum_i\\epsilon_{0i}\\beta_{i} = 0$ since each column of X must be decorrelated from the noise $\\epsilon_0$ "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A more general version of this can be written in the following way, with a small bit of matrix algebra:\n",
      "\n",
      "\n",
      "$$\n",
      "\\begin{eqnarray}\n",
      "SSR(X_0) - SSR(X) & = & (Y^T(I-P_{X_0})Y - Y^T(I-P_{X})Y)  \\\\ \n",
      "                & = & Y^TY - YP_{X_0}Y - Y^TY + YP_{X}Y \\\\\n",
      "                & = & Y^TP_{X}Y - Y^TP_{X_0}Y\n",
      "\\end{eqnarray}\n",
      "$$\n",
      "\n",
      "But $Y^TP_{X}Y$ is also $Y^TP_{X}P_{X}Y = Y^TX(X^TX)^{-1}X^T X(X^TX)^{-1}X^T Y =  \\beta^T X^T X \\beta$\n",
      "\n",
      "The first equality is because $P_{X} = P_{X}P_{X}$, the second by replacing  $P_X$ by $X(X^TX)^{-1}X^T $. \n",
      "\n",
      "Now, we can partition $X$ in $[X_t X_0]$ where $X_0$ is the null model and $X_t$ is the tested part (with parameters $\\beta_t$), and if they are orthogonal, then   \n",
      "\n",
      "$$\n",
      "SSR(X_0) - SSR(X)  = \\beta^T X^T X \\beta - \\beta_0^T X_0^T X_0 \\beta_0  =  \\beta_t^T X_t^T X_t \\beta_t\n",
      "$$\n",
      "\n",
      "and therefore\n",
      "\n",
      "$$\n",
      "SSR(X_0) - SSR(X)  = \\beta_t^T X_t^T X_t \\beta_t\n",
      "$$\n",
      "\n",
      "which corresponds to the sum of square of the means, weighted by the number of observation (see this by doing the dot product of $X_t \\beta_t$ by itself. Note what is $ X_t \\beta_t$ : the \"means\". "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "L0 = np.eye(p)[:,3:]\n",
      "(F, n1, n2) = F_test(Y, X, L0)\n",
      "print (F, n1, n2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "     [[ 27.05935053]] 3 1\n",
        "     [[ 13.51305476]] 30 3\n",
        "(array([[ 27.0332089]]), 2, 27)\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split X in Xt and X0 :\n",
      "X0 = X[:,[3]]\n",
      "# orthogonolize the three first columns of X : this is what we want to test\n",
      "Xt = R_proj(X0, X[:,:3])\n",
      "# recreate the all matrix\n",
      "Xall = np.hstack((Xt, X0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "betah = lin.pinv(Xall).dot(Y)\n",
      "betah_t = betah[:3,:]\n",
      "\n",
      "print \"betah_t : \", betah_t\n",
      "\n",
      "tmp = Xt.dot(betah_t)\n",
      "SSRXt = tmp.T.dot(tmp)\n",
      "print \"Using the sum of square of the beta_t : SSRXt = %f \\n\" % SSRXt\n",
      "\n",
      "SSRX_SSRX0 =  Y.T.dot(proj(Xall, Y)) - Y.T.dot(proj(X0, Y))\n",
      "\n",
      "print \"Using SSR X - SSR X0 : SSRX_SSRX0 = %f \\n\" % SSRX_SSRX0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "betah_t :  [[ 0.87996109]\n",
        " [-1.3187404 ]\n",
        " [ 0.43877931]]\n",
        "Using the sum of square of the beta_t : SSRXt = 27.059351 \n",
        "\n",
        "Using SSR X - SSR X0 : SSRX_SSRX0 = 27.059351 \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import f as Fdist\n",
      "Fdist.sf(F,n1,n2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "array([[  3.58143893e-07]])"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check if we have no rank deficiency\n",
      "# recreate the original\n",
      "X = np.hstack((oneway_anov, intercept))\n",
      "\n",
      "Xt = X.dot(np.asarray([[1, -1, 0, 0],[0, 1, -1, 0]]).T)\n",
      "X0 = X[:,[3]]\n",
      "Xall = np.hstack((Xt, X0))\n",
      "\n",
      "betah = np.linalg.pinv(Xall).dot(Y)\n",
      "\n",
      "#print Xall\n",
      "#print Xall.T.dot(Xall)\n",
      "\n",
      "betah_t = betah[:2,:]\n",
      "print \" betah_t \", betah_t\n",
      "\n",
      "tmp = Xt.dot(betah_t)\n",
      "SSRXt = tmp.T.dot(tmp)\n",
      "print \"Using the sum of square of the beta_t : SSRXt = %f \\n\" % SSRXt\n",
      "\n",
      "SSRX_SSRX0 =  Y.T.dot(proj(Xall, Y)) - Y.T.dot(proj(X0, Y))\n",
      "\n",
      "print \"Using SSR X - SSR X0 : SSRX_SSRX0 = %f \\n\" % SSRX_SSRX0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " betah_t  [[ 0.50142161]\n",
        " [ 0.02168588]]\n",
        "Using the sum of square of the beta_t : SSRXt = 4.820403 \n",
        "\n",
        "Using SSR X - SSR X0 : SSRX_SSRX0 = 4.820403 \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now - let's make the F test with a contrast. We just assume that we derived it - the formula is \n",
      "\n",
      "$$\n",
      "\\begin{equation} \n",
      "  F_{\\nu_1, \\nu_2}  =  \\frac{\\hat\\beta^T \\Lambda (\\Lambda^T (X^TX)^- \\Lambda)^- \\Lambda^T \\hat\\beta / \\nu_{1} }{MSE} \\\\ \n",
      "\\end{equation}\n",
      "$$\n",
      "\n",
      "where the $MSE$ is the mean square error $SSR(X)/\\nu_2$.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def F_con(X, Y, L, verbose=False):\n",
      "    \n",
      "    # check that the contrast makes sense\n",
      "    B = lin.pinv(X).dot(Y)\n",
      "    \n",
      "    # Numerator\n",
      "    piXtX = lin.pinv(X.T.dot(X))\n",
      "    piLtpiXtXL = lin.pinv(L.T.dot(piXtX).dot(L))\n",
      "    LtB = L.T.dot(B)\n",
      "    Fnum = LtB.T.dot(piLtpiXtXL).dot(LtB)\n",
      "    \n",
      "    # SSRX ?\n",
      "    SSRX = Y.T.dot(Y) - B.T.dot(X.T.dot(X)).dot(B)\n",
      "    v1 = matrix_rank(L)\n",
      "    v2 = X.shape[0] - matrix_rank(X)\n",
      "    \n",
      "    if verbose:\n",
      "        print 'Fnum: %f, df1=%d, Fdenom: %f, df2=%d,  \\n' % (Fnum, v1, SSRX, v2)\n",
      "    \n",
      "    return (Fnum/v1)/(SSRX/v2), v1, v2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "B = lin.pinv(X).dot(Y)\n",
      "print B\n",
      "#print X\n",
      "L = np.array([[1., -1., 0, 0],[0., 1., -1., 0]]).T\n",
      "print L\n",
      "F,v1,v2 = F_con(X, Y, L, verbose = True)\n",
      "print F,v1,v2 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "objects are not aligned",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-71-e62367a14bfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF_con\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-70-ecf4a53ba7b2>\u001b[0m in \u001b[0;36mF_con\u001b[1;34m(X, Y, L, verbose)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Numerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mpiXtX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mpiLtpiXtXL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpiXtX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mLtB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mFnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLtB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpiLtpiXtXL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLtB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: objects are not aligned"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.0565886 ]\n",
        " [ 0.82571892]\n",
        " [ 0.36905904]\n",
        " [ 1.90725234]\n",
        " [ 0.34411422]\n",
        " [ 2.25136656]]\n",
        "[[ 1.  0.]\n",
        " [-1.  1.]\n",
        " [ 0. -1.]\n",
        " [ 0.  0.]]\n"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.  0.  0.  1.  0.  1.]\n",
        " [ 1.  0.  0.  1.  0.  1.]\n",
        " [ 1.  0.  0.  1.  0.  1.]\n",
        " [ 1.  0.  0.  1.  0.  1.]\n",
        " [ 1.  0.  0.  1.  0.  1.]\n",
        " [ 1.  0.  0.  0.  1.  1.]\n",
        " [ 1.  0.  0.  0.  1.  1.]\n",
        " [ 1.  0.  0.  0.  1.  1.]\n",
        " [ 1.  0.  0.  0.  1.  1.]\n",
        " [ 1.  0.  0.  0.  1.  1.]\n",
        " [ 0.  1.  0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  0.  1.  1.]\n",
        " [ 0.  1.  0.  0.  1.  1.]\n",
        " [ 0.  1.  0.  0.  1.  1.]\n",
        " [ 0.  1.  0.  0.  1.  1.]\n",
        " [ 0.  1.  0.  0.  1.  1.]\n",
        " [ 0.  0.  1.  1.  0.  1.]\n",
        " [ 0.  0.  1.  1.  0.  1.]\n",
        " [ 0.  0.  1.  1.  0.  1.]\n",
        " [ 0.  0.  1.  1.  0.  1.]\n",
        " [ 0.  0.  1.  1.  0.  1.]\n",
        " [ 0.  0.  1.  0.  1.  1.]\n",
        " [ 0.  0.  1.  0.  1.  1.]\n",
        " [ 0.  0.  1.  0.  1.  1.]\n",
        " [ 0.  0.  1.  0.  1.  1.]\n",
        " [ 0.  0.  1.  0.  1.  1.]]\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example 2: 2 ways anova"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we quickly take the example of a 2 ways anova - with no interaction. Say we have two groups of subjects (eg patients and normal controls) and they are divided in 3 groups each, depending for instance on rehabilitation therapy. Let's do the desing matrix:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# simplifiy the notations\n",
      "from numpy import kron, ones, eye, zeros\n",
      "\n",
      "nbs1= 10; g1 = 3; g2 = 2;\n",
      "n = nbs1*g1\n",
      "factor1 = kron(eye(g1), ones((nbs1,1)))\n",
      "factor2 = kron(eye(g2), ones((n/6,1)))\n",
      "factor2 = kron(ones((g1,1)), factor2)\n",
      "intercept = ones((n,1))\n",
      "\n",
      "X = np.hstack((factor1, factor2, intercept))\n",
      "print X\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.  0.  0.  1.  0.  1.]\n",
        " [ 1.  0.  0.  1.  0.  1.]\n",
        " [ 1.  0.  0.  1.  0.  1.]\n",
        " [ 1.  0.  0.  1.  0.  1.]\n",
        " [ 1.  0.  0.  1.  0.  1.]\n",
        " [ 1.  0.  0.  0.  1.  1.]\n",
        " [ 1.  0.  0.  0.  1.  1.]\n",
        " [ 1.  0.  0.  0.  1.  1.]\n",
        " [ 1.  0.  0.  0.  1.  1.]\n",
        " [ 1.  0.  0.  0.  1.  1.]\n",
        " [ 0.  1.  0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  1.  0.  1.]\n",
        " [ 0.  1.  0.  0.  1.  1.]\n",
        " [ 0.  1.  0.  0.  1.  1.]\n",
        " [ 0.  1.  0.  0.  1.  1.]\n",
        " [ 0.  1.  0.  0.  1.  1.]\n",
        " [ 0.  1.  0.  0.  1.  1.]\n",
        " [ 0.  0.  1.  1.  0.  1.]\n",
        " [ 0.  0.  1.  1.  0.  1.]\n",
        " [ 0.  0.  1.  1.  0.  1.]\n",
        " [ 0.  0.  1.  1.  0.  1.]\n",
        " [ 0.  0.  1.  1.  0.  1.]\n",
        " [ 0.  0.  1.  0.  1.  1.]\n",
        " [ 0.  0.  1.  0.  1.  1.]\n",
        " [ 0.  0.  1.  0.  1.  1.]\n",
        " [ 0.  0.  1.  0.  1.  1.]\n",
        " [ 0.  0.  1.  0.  1.  1.]]\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Simulate the data : "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print csignal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.5]\n",
        " [-0.5]\n",
        " [ 0. ]\n",
        " [ 2. ]\n",
        " [ 0. ]\n",
        " [ 3. ]]\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n, p = X.shape\n",
      "f1_fx = np.asarray([1., -1., 0]) * .5\n",
      "f2_fx = np.asarray([2., 0.])\n",
      "offset = np.asarray([3.])\n",
      "\n",
      "csignal = np.hstack((f1_fx, f2_fx, offset)).reshape(p,1)\n",
      "\n",
      "Y = np.random.randn(n, 1)\n",
      "signal = X.dot(csignal)\n",
      "\n",
      "Y = Y +  signal\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print signal\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 5.5]\n",
        " [ 5.5]\n",
        " [ 5.5]\n",
        " [ 5.5]\n",
        " [ 5.5]\n",
        " [ 3.5]\n",
        " [ 3.5]\n",
        " [ 3.5]\n",
        " [ 3.5]\n",
        " [ 3.5]\n",
        " [ 4.5]\n",
        " [ 4.5]\n",
        " [ 4.5]\n",
        " [ 4.5]\n",
        " [ 4.5]\n",
        " [ 2.5]\n",
        " [ 2.5]\n",
        " [ 2.5]\n",
        " [ 2.5]\n",
        " [ 2.5]\n",
        " [ 5. ]\n",
        " [ 5. ]\n",
        " [ 5. ]\n",
        " [ 5. ]\n",
        " [ 5. ]\n",
        " [ 3. ]\n",
        " [ 3. ]\n",
        " [ 3. ]\n",
        " [ 3. ]\n",
        " [ 3. ]]\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Test for factor 1: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Fc1 = np.asarray([[1, -1, 0], [0, 1, -1]])\n",
      "\n",
      "F_fill = zeros((2, p-3))\n",
      "\n",
      "Fc = np.hstack((Fc1, F_fill))\n",
      "print Fc\n",
      "print p \n",
      "\n",
      "(f, n1, n2) = F_con(X, Y, Fc.T, verbose=True)\n",
      "\n",
      "# compute the P value:\n",
      "Fdist.sf(f,n1,n2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1. -1.  0.  0.  0.  0.]\n",
        " [ 0.  1. -1.  0.  0.  0.]]\n",
        "6\n",
        "Fnum: 1.796334, df1=2, Fdenom: 25.258972, df2=26,  \n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": [
        "array([[ 0.40937548]])"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Exercise 1 : F contrast on factor 2"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Exercise 2: create the interaction term - and the contrast associated with it. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "F test from contrast : the derivation - Please don't look at this  ...."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We assume from now on that the contrast of parameters we would like to test may\n",
      "concern multiple constraints on the $\\beta$, and will denote those constraints\n",
      "by $\\Lambda \\beta = 0$. \n",
      "\n",
      "Setting  $\\Lambda^T \\beta = 0$ is also setting  $H^T X \\beta =\n",
      "0$ for some matrix $H$ (the number of columns in $H$ is the number of columns\n",
      "in $\\Lambda$).  \n",
      "\n",
      "If we have a (legitimate) contrast of the parameters, what does\n",
      "$H$ look like? How does this relate to a reduced model? Why is all this\n",
      "relevant for fMRI?  It is interesting to understand what $H$ is. While $\\Lambda$\n",
      "puts some constraints on the parameters of the model, $H$ is the equivalent\n",
      "constraint on the space of $X$ \\citep{Christensen2002}. The reduced model that is to be tested is $ Y =\n",
      "X \\beta + \\epsilon $ $\\textbf{and}$ $H^T X \\beta =0$, or, equivalently, that $E(Y)\n",
      "\\in C(X)$ $\\textbf{and}$ $E(Y) \\in C(H)^{\\perp}$ where $C(H)^{\\perp}$ is the space\n",
      "orthogonal to $H$ (This is the set of vectors with zero correlation\n",
      "with any vector of $H$).  The reduced model should therefore be a matrix $X_0$\n",
      "such that $X_0 \\in C(X)$ $\\textbf{and}$ $X_0 \\in C(H)^{\\perp}$.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "By choosing $H = X^{T-} \\Lambda$, we impose the constraint on $X$ that\n",
      "corresponds to $\\Lambda^T \\beta = 0$.  Since $H^T E(Y) = H^T X \\beta =\n",
      "\\Lambda^T X^- X \\beta = \\Lambda^T \\beta = 0 $, we have $E(Y) \\in C(H)^\\perp $\n",
      "with this particular choice of $H$. Also, $H \\in C(X)$, so $H$ is a matrix \n",
      "that imposes a constraint on $X$ within the space of $X$, and is the part of\n",
      "$X$ that is being tested. The part of $X$ that is not being tested, the reduced\n",
      "model, can be found easily by projecting the orthogonal space of $H$ onto $X$ ,\n",
      "so we have $X_0 = P_X R_H  = P_X(I - P_H) = P_X - P_H$. Testing for $\\Lambda\n",
      "\\beta = 0$ is equivalent to testing for the reduced model $Y = X_0 \\gamma +\n",
      "\\epsilon$ with $X_0$ as defined above. Having defined $X_0$ as above, we have\n",
      "$P_X = P_{X_0} + P_H$.\n",
      "\n",
      "Now, the numerator of the F test can be rewritten in a much simpler\n",
      "way, as a function of $\\Lambda$ only:\n",
      "\n",
      "\\begin{eqnarray}\n",
      "  Y^T (P_H) Y & =  & Y^T X (X^T X)^- X^T H(H^T H)^- H^T X (X^T X)^- X^T Y / r(\\Lambda) \\\\ %\\nonumber\n",
      "  & =  & \\hat\\beta^T \\Lambda (\\Lambda^T (X^TX)^- \\Lambda)^- \\Lambda^T \\hat\\beta / r(\\Lambda)  \n",
      "\\end{eqnarray}\n",
      "Where $r(\\Lambda)$ is the rank of $\\Lambda$, and the F test can be rewritten as:\n",
      "\n",
      "\\begin{equation} \n",
      "  F_{\\nu_1, \\nu_2}  =  \\frac{\\hat\\beta^T \\Lambda (\\Lambda^T (X^TX)^- \\Lambda)^- \\Lambda^T \\hat\\beta / \\nu_{1} }{MSE} \\\\ \n",
      "\\end{equation}\n",
      "where the $MSE$ is the mean square error $SSR(X)/\\nu_2$.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}